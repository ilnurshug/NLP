{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = [line.rstrip('\\n') for line in open('data-train.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Сгруппируем все предложения для конкретного языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_filter(text):\n",
    "    return [c.lower() for c in text if c.isalpha() or c == ' ']\n",
    "\n",
    "l = {}\n",
    "l_cnt = {}\n",
    "\n",
    "for i in range(1, len(lines)):\n",
    "    lang, text = lines[i].split('\\t', 1)\n",
    "    \n",
    "    f = l_cnt.get(lang, 0)\n",
    "    l_cnt[lang] = f + 1\n",
    "    \n",
    "    if (l.get(lang) is None):\n",
    "        l[lang] = [text]\n",
    "    else:\n",
    "        l[lang].append(text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk import trigrams\n",
    "\n",
    "words_fd = {}\n",
    "\n",
    "for lang, texts in l.items():\n",
    "    words_fd[lang] = FreqDist()\n",
    "    for text in texts:\n",
    "        symbols = []\n",
    "        for c in text:\n",
    "            symbols.append(c)\n",
    "#             symbols.append(c.lower())\n",
    "#             if c.isalpha() or c == ' ':\n",
    "#                 symbols.append(c.lower())\n",
    "        words_fd[lang].update(trigrams(symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель 1\n",
    "Для каждого языка построим триграмную языковую модель со вглаживанием KneserNey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.probability import KneserNeyProbDist\n",
    "\n",
    "kn = {}\n",
    "for lang in l.keys():\n",
    "    kn[lang] = KneserNeyProbDist(words_fd[lang])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_arr = ['be','bg','cs','de','el','en','es','fr','hr','hsb','hy','it','la','lt','lv','mk','nl','pl','pt','ro','ru','sk','sl','sr','sv','uk']\n",
    "\n",
    "l_ids = {}\n",
    "l_i = 0\n",
    "l_from_id = {}\n",
    "\n",
    "for lang in l_arr:\n",
    "    l_ids[lang] = l_i\n",
    "    l_from_id[l_i] = lang\n",
    "    l_i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация\n",
    "Для классификации языка текста, воспользуемся формулой Байеса:\n",
    "$$ P(l \\mid t) = \\frac{P(t \\mid l) P(l)}{P(t)} \\propto P(t \\mid l) P(l), $$\n",
    "где $ l $ - язык, $ t $ - текст, $ P(l) $ - априорная вероятность языка $ l $ и $ P(t\\mid l) $ - вероятность текста  в рамках языковой модели. \n",
    "\n",
    "Тогда получаем, что $$ l' = \\arg\\max\\limits_{l} \\left\\{ softmax \\left( P(t \\mid l_1) P(l_1), \\ldots, P(t \\mid l_n) P(l_n) \\right) \\right\\} . $$\n",
    "Заметим, что разные языки встречаются в обучающей выборке с разной частотой, поэтому $ P(l) $ несет в себе важную информацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(w, t=1.0):\n",
    "    m = np.max(w)\n",
    "    e = np.exp((np.array(w) - m) / t)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def lang_prob(lang):\n",
    "    return l_cnt[lang] / (len(lines) - 1)\n",
    "\n",
    "def langs_prob(text):\n",
    "    probs = [0] * len(l.keys())\n",
    "    \n",
    "    for lang in l.keys():\n",
    "        prob = 0.0\n",
    "        for i in range(2, len(text)):\n",
    "            prob += math.log(kn[lang].prob((text[i-2], text[i-1], text[i])) + 0.1, 2)\n",
    "        prob += math.log(lang_prob(lang), 2)\n",
    "        probs[l_ids[lang]] = prob\n",
    "        \n",
    "    return softmax(probs)\n",
    "\n",
    "def predict_lang(text):\n",
    "    return l_from_id[np.argmax(langs_prob(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.rstrip('\\n') for line in open('data-test.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты\n",
    "При отправке на kaggle: <b>0.02055</b>\n",
    "### Модификации\n",
    "Были предприняты различные попытки по \"чистке\" входных данных:\n",
    "1. Перевод всех символов в нижний регистр\n",
    "2. Удаление всех не alphanum символов (При отправке на kaggle: <b>0.02314</b>)\n",
    "3. Модификации 1 и 2 вместе (При отправке на kaggle: <b>0.02832</b>)\n",
    "\n",
    "К сожалению, это все приводило только к ухудшению результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "test_out = open('test.out', 'w')\n",
    "writer = csv.writer(test_out)\n",
    "writer.writerow(['id', 'be','bg','cs','de','el','en','es','fr','hr','hsb','hy','it','la','lt','lv','mk','nl','pl','pt','ro','ru','sk','sl','sr','sv','uk'])\n",
    "\n",
    "l_count = len(l.keys())\n",
    "\n",
    "for i in range(1, len(lines)):\n",
    "    k, text = lines[i].split('\\t', 1)\n",
    "\n",
    "#     text = text_filter(text)\n",
    "\n",
    "    probs = [0] * l_count\n",
    "    probs[l_ids[predict_lang(text)]] = 1\n",
    "    probs = [k] + probs\n",
    "    writer.writerow(probs)\n",
    "        \n",
    "test_out.flush()\n",
    "test_out.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
