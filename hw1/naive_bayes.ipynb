{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.rstrip('\\n') for line in open('data-train.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "def prepare(text):\n",
    "    text = nltk.sent_tokenize(text)\n",
    "    words = []\n",
    "    for s in text:\n",
    "        for w in preprocess(s):\n",
    "            words.append(w)\n",
    "    return words    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Каждое предложение переводим в нижний регистр и выполняем токенизацию. \n",
    "\n",
    "Каждый объект <i>(язык, текст)</i> превращаем в <i>(язык, список слов из текста)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1, len(lines)):\n",
    "    lang, text = lines[i].split('\\t', 1)\n",
    "    data.append((prepare(text), lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение train, validate\n",
    "Выполняем StratifiedShuffleSplit данных из data-train (с соблюдением пропрорций классов, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X = data\n",
    "y = []\n",
    "for i in range(len(data)):\n",
    "    y.append(data[i][1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "    \n",
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "    \n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['чего', 'он', 'вообще', 'хотел', 'добиться', 'никто', 'понять', 'не', 'мог', 'он', 'заехал', 'в', 'лес', 'вышел', 'осмотрелся', 'затряс', 'головой', 'снова', 'влез', 'в', 'машину', 'и', 'они', 'поехали', 'дальше', 'то', 'же', 'самое', 'произошло', 'и', 'посреди', 'вспаханного', 'поля', 'и', 'на', 'подвесном', 'мосту', 'и', 'на', 'крыше', 'многоэтажной', 'стоянки', 'папа', 'сошел', 'с', 'ума', 'да', 'скучно', 'спросил', 'дудли', 'у', 'матери', 'вечером', 'того', 'же', 'дня', 'дядя', 'вернон', 'привез', 'их', 'на', 'берег', 'моря', 'запер', 'в', 'машине', 'и', 'исчез'], 'ru')\n"
     ]
    }
   ],
   "source": [
    "def conv(X):\n",
    "    X_new = []\n",
    "    for i in range(len(X)):\n",
    "        X_new.append((X[i][0], X[i][1]))\n",
    "    return X_new\n",
    "\n",
    "X_train = conv(X_train)\n",
    "X_test = conv(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_arr = ['be','bg','cs','de','el','en','es','fr','hr','hsb','hy','it','la','lt','lv','mk','nl','pl','pt','ro','ru','sk','sl','sr','sv','uk']\n",
    "\n",
    "l_ids = {}\n",
    "l_i = 0\n",
    "l_from_id = {}\n",
    "\n",
    "for lang in l_arr:\n",
    "    l_ids[lang] = l_i\n",
    "    l_from_id[l_i] = lang\n",
    "    l_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import nltk.classify.util, nltk.metrics\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.metrics.scores import precision, recall\n",
    "\n",
    "\n",
    "def evaluate_classifier(features_extractor, train, test):\n",
    "    \"\"\"\n",
    "         features_extractor - function for extraction features from review. \n",
    "         train, test - samples\n",
    "    \"\"\"\n",
    "    train_feats = [(features_extractor(review), sent) for review, sent in train]\n",
    "    test_feats = [(features_extractor(review), sent) for review, sent in test]\n",
    " \n",
    "    classifier = NaiveBayesClassifier.train(train_feats)\n",
    "#     refsets = defaultdict(set)\n",
    "#     testsets = defaultdict(set)\n",
    " \n",
    "#     for i, (feats, label) in enumerate(test_feats):\n",
    "#         observed = classifier.classify(feats)\n",
    " \n",
    "    print('accuracy:', nltk.classify.util.accuracy(classifier, test_feats))\n",
    "    classifier.show_most_informative_features()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель 1\n",
    "Попробуем NaiveBayesClassifier c признаками bag-of-symbols\n",
    "### Результат на validate:\n",
    "accuracy: 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9649670840325287\n",
      "Most Informative Features\n",
      "                       ě = True               cs : ru     = 104004.6 : 1.0\n",
      "                       ι = True               el : ru     = 103911.3 : 1.0\n",
      "                       ί = True               el : ru     = 103911.3 : 1.0\n",
      "                       έ = True               el : ru     = 103911.3 : 1.0\n",
      "                       κ = True               el : ru     = 103911.3 : 1.0\n",
      "                       γ = True               el : ru     = 103911.3 : 1.0\n",
      "                       α = True               el : ru     = 103911.3 : 1.0\n",
      "                       ε = True               el : ru     = 103911.3 : 1.0\n",
      "                       ο = True               el : ru     = 103911.3 : 1.0\n",
      "                       ν = True               el : ru     = 103911.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(sym, True) for word in words for sym in word])\n",
    "\n",
    "evaluate_classifier(word_feats, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель 2\n",
    "Попробуем NaiveBayesClassifier c признаками bag-of-symbols, и добавим к ним популярные биграмы символов.\n",
    "### Результат на validate:\n",
    "accuracy: 0.98\n",
    "### Результат проверки на kaggle:\n",
    "0.35437 - значительно хуже результатов триграмной языковой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9899574028656254\n",
      "Most Informative Features\n",
      "                       ě = True               cs : ru     = 104004.6 : 1.0\n",
      "                       ι = True               el : ru     = 103911.3 : 1.0\n",
      "                       ί = True               el : ru     = 103911.3 : 1.0\n",
      "                       έ = True               el : ru     = 103911.3 : 1.0\n",
      "                       ε = True               el : ru     = 103911.3 : 1.0\n",
      "                       κ = True               el : ru     = 103911.3 : 1.0\n",
      "                       α = True               el : ru     = 103911.3 : 1.0\n",
      "                       ο = True               el : ru     = 103911.3 : 1.0\n",
      "                       γ = True               el : ru     = 103911.3 : 1.0\n",
      "                       ν = True               el : ru     = 103911.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "\n",
    "def freq_scorer(n_ii, n_ix_xi_tuple, n_xx):\n",
    "    return n_ii / n_xx\n",
    "\n",
    "def bigram_word_feats(words, score_fn=freq_scorer, n=10):\n",
    "    symbols = [s for w in words for s in w]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(symbols)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(ngram, True) for ngram in itertools.chain(symbols, bigrams)])\n",
    " \n",
    "clf = evaluate_classifier(bigram_word_feats, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = [line.rstrip('\\n') for line in open('data-test.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "test_out = open('test.out', 'w')\n",
    "writer = csv.writer(test_out)\n",
    "writer.writerow(['id', 'be','bg','cs','de','el','en','es','fr','hr','hsb','hy','it','la','lt','lv','mk','nl','pl','pt','ro','ru','sk','sl','sr','sv','uk'])\n",
    "\n",
    "l_count = len(l_arr)\n",
    "\n",
    "for i in range(1, len(lines)):\n",
    "    k, text = lines[i].split('\\t', 1)\n",
    "    text = prepare(text)\n",
    "\n",
    "    probs = [0] * l_count\n",
    "    p = clf.classify(bigram_word_feats(text))\n",
    "    probs[l_ids[p]] = 1\n",
    "    probs = [k] + probs\n",
    "    writer.writerow(probs)\n",
    "\n",
    "test_out.flush()\n",
    "test_out.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
